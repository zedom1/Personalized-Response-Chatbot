{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preppy import RankPreppy\n",
    "from user import UserModel\n",
    "from rank import RankModel\n",
    "from seq2seq import Seq2SeqModel\n",
    "from tensorflow.contrib.seq2seq import *\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'sentence_embedding': 0,  # sentence vector size, read from seq2seq params\n",
    "    'user_embeding': 0,   # user  embedding size, read from user params\n",
    "    \n",
    "    'p_size': 64,  # hidden layer size, according to the paper\n",
    "    'r_size': 64,   # hidden layer size, according to the paper\n",
    "    'f_size': 64,   # hidden layer size, according to the paper\n",
    "    's_size': 64,  # hidden layer size, according to the paper\n",
    "    \n",
    "    'epochs': 1,\n",
    "    'batch_size': 32,\n",
    "    \n",
    "    'grad_clip': 5.0,\n",
    "    'learning_rate': 0.001,\n",
    "    \n",
    "    'save_path' : './Model/Rank/model.ckpt',\n",
    "    'user_embedding_file': ''\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataset by reading the train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(x):\n",
    "    x['label'] = tf.expand_dims(tf.convert_to_tensor(x['label']),0)\n",
    "    x['user'] = tf.expand_dims(tf.convert_to_tensor(x['user']),0)\n",
    "    return x\n",
    "\n",
    "def deflate(x):\n",
    "    x['label'] = tf.squeeze(x['label'])\n",
    "    x['user'] = tf.squeeze(x['user'])\n",
    "    return x\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "def save_params(params, path='./Model/Rank/params.pkl'):\n",
    "    with open(path, 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "def load_params(path='./Model/Rank/params.pkl'):\n",
    "    with open(path, 'rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preppy = pickle.load(open('./data/rank/preppy.pkl','rb'))\n",
    "dataset_train = tf.data.TFRecordDataset(['./data/rank/train.tfrecord']).map(preppy.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': [11], 'query': [[52, 5, 101, 257, 16, 1234, 33, 720, 153, 2594, 16, 6, 225, 974, 7, 159, 309, 5, 991, 3, 4294, 5, 2423, 16, 4798, 288, 52, 489, 5, 341, 5338]], 'response_0': [[3811, 16, 1547, 1595, 337, 90, 1750, 3, 70, 81, 497, 866, 52, 174, 2551, 14]], 'response_1': [[5, 119, 3298, 38, 14, 462, 3, 1259, 261, 1482, 565, 462, 973, 819, 11, 727, 1072, 1259]], 'response_2': [[462, 973, 974, 51, 2975, 769, 3]], 'response_3': [[3267, 409, 974, 2688, 727, 1378, 4141, 81, 543, 1530, 12, 16, 2423, 158, 397, 16, 838, 119, 123, 102, 2133, 210, 3, 494, 3, 4141, 27]], 'response_4': [[462, 973, 974, 11, 727, 253, 253, 30, 727, 73, 83, 462, 975, 410]], 'response_5': [[4735, 25, 49, 621, 225, 4735, 3449, 270, 963, 6, 18, 1937, 25, 225, 174, 304, 621, 25]], 'response_6': [[225, 341, 304, 2621, 2500, 25, 740, 25, 11, 225, 2901, 288, 25, 2901, 16, 2991, 106, 277, 225, 7, 884, 25, 2621, 92, 225, 809, 304, 556, 81, 2301, 2815, 16, 3239, 16, 1520, 304, 2971, 25]], 'response_7': [[3, 52, 6, 1649, 410, 1821, 25, 1176, 3792, 467, 174, 481, 14, 2096, 225, 149, 674, 3792, 467, 1286, 467, 3495, 159, 160, 39, 39]], 'response_8': [[5, 121, 1434, 514, 819, 92, 3, 16, 3, 77, 111, 1435, 304, 69, 3, 60, 1436, 753, 7, 283, 1434, 3, 639, 543, 864, 196, 1437, 3, 3]], 'response_9': [[819, 585, 3, 92, 16, 1259, 271, 5605, 683, 30, 1259, 372, 5, 4147, 819, 3, 595, 5, 81, 2724, 612, 163, 158, 5, 1150, 1259, 4602, 991, 341, 55, 66, 159, 2786, 1022, 3030, 2414]]}\n"
     ]
    }
   ],
   "source": [
    "val = pickle.load(open('./data/rank/val.pkl','rb'))\n",
    "for i in range(len(val)):\n",
    "    for key in val[i]:\n",
    "        if key != \"user\":\n",
    "            val[i][key] = [preppy.sentence_to_id_list(val[i][key])]\n",
    "        else:\n",
    "            val[i][key] = [val[i][key]]\n",
    "print(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': TensorShape([Dimension(None)]),\n",
       " 'response': TensorShape([Dimension(None)]),\n",
       " 'user': TensorShape([]),\n",
       " 'label': TensorShape([])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_train = dataset_train.map(expand).padded_batch(32,padded_shapes={\n",
    "    \"query\":tf.TensorShape([None]),\n",
    "    \"response\":tf.TensorShape([None]),\n",
    "    \"label\":1,\n",
    "    \"user\":1\n",
    "}, drop_remainder=True).map(deflate)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, batched_train.output_types, batched_train.output_shapes)\n",
    "\n",
    "next_item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': TensorShape([Dimension(32), Dimension(None)]),\n",
       " 'response': TensorShape([Dimension(32), Dimension(None)]),\n",
       " 'user': TensorShape([Dimension(32)]),\n",
       " 'label': TensorShape([Dimension(32)])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_train.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_train = batched_train.make_initializable_iterator()\n",
    "\n",
    "handle_train = sess.run(iterator_train.string_handle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/Seq2seq/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "seqParams = load_params('./Model/Seq2seq/params.pkl')\n",
    "seqParams[\"vocab_size\"] = len(preppy.vocab)\n",
    "\n",
    "seqModel = Seq2SeqModel(seqParams)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, seqParams[\"save_path\"])\n",
    "\n",
    "params[\"sentence_embedding\"] = seqParams[\"hidden_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "userParams = load_params('./Model/User/params.pkl')\n",
    "params[\"user_embedding_file\"] = userParams[\"embedding_path\"]\n",
    "params[\"user_embedding\"] = userParams[\"embedding_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Model/User/user_embedding.pkl\",\"rb\") as user_emb:\n",
    "    user_embedding = pickle.load(user_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 50)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(user_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = RankModel(params)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Model/Rank/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, params[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training\n",
      "0.47476962\n",
      "0.3276026\n",
      "0.41601965\n",
      "0.48160124\n",
      "0.24021786\n",
      "0.658562\n",
      "0.43334627\n",
      "0.398009\n",
      "0.5676975\n",
      "0.37094367\n",
      "0.59196657\n",
      "0.31432384\n",
      "0.23204938\n",
      "0.4393373\n",
      "0.49548697\n",
      "0.34006107\n",
      "0.525295\n",
      "0.445009\n",
      "0.4810596\n",
      "0.2571851\n",
      "0.32639915\n",
      "0.4679556\n",
      "0.27033445\n",
      "0.52282244\n",
      "0.5665869\n",
      "0.33226573\n",
      "0.38346237\n",
      "0.34524184\n",
      "0.21056077\n",
      "0.3890518\n",
      "0.40338176\n",
      "0.3719858\n",
      "0.43448615\n",
      "0.4934253\n",
      "0.32570815\n",
      "0.31917977\n",
      "0.42883348\n",
      "0.18388817\n",
      "0.2914665\n",
      "0.32172972\n",
      "0.42681658\n",
      "0.2906142\n",
      "0.44946837\n",
      "0.2807832\n",
      "0.39934883\n",
      "0.1729584\n",
      "0.20328087\n",
      "0.2965841\n",
      "0.39577883\n",
      "0.36500454\n",
      "0.16734914\n",
      "0.40122384\n",
      "0.34947228\n",
      "0.33299136\n",
      "0.19055451\n",
      "0.49160913\n",
      "0.3640092\n",
      "0.100351974\n",
      "0.3093309\n",
      "0.3120603\n",
      "0.15249136\n",
      "0.24589728\n",
      "0.44603905\n",
      "0.3807531\n",
      "0.38060066\n",
      "0.36607006\n",
      "0.40813074\n",
      "0.23560803\n",
      "0.42502987\n",
      "0.30694595\n",
      "0.17251647\n",
      "0.23285148\n",
      "0.3350166\n",
      "0.3263651\n",
      "0.23926188\n",
      "0.46863753\n",
      "0.37282532\n",
      "0.2286796\n",
      "0.3077584\n",
      "0.38507038\n",
      "0.39333594\n",
      "0.530054\n",
      "0.29573473\n",
      "0.2626981\n",
      "0.39301366\n",
      "0.5629115\n",
      "0.38289672\n",
      "0.43868953\n",
      "0.370881\n",
      "0.23311399\n",
      "0.47641358\n",
      "0.43305534\n",
      "0.2984274\n",
      "0.37250194\n",
      "0.25178134\n",
      "0.25738943\n",
      "0.6346867\n",
      "0.3202028\n",
      "0.19057319\n",
      "0.36061653\n",
      "0.5941882\n",
      "0.30761045\n",
      "0.2931147\n",
      "0.3838514\n",
      "0.5105119\n",
      "0.2868987\n",
      "0.33165497\n",
      "0.26127848\n",
      "0.36342028\n",
      "0.31154406\n",
      "0.42620778\n",
      "0.25756145\n",
      "0.43493658\n",
      "0.19591382\n",
      "0.288332\n",
      "0.28088218\n",
      "0.37821224\n",
      "0.22469683\n",
      "0.29266277\n",
      "0.459656\n",
      "0.3815031\n",
      "0.23399736\n",
      "0.21734375\n",
      "0.2749858\n",
      "0.28308165\n",
      "0.21533778\n",
      "0.31873757\n",
      "0.21875332\n",
      "0.53315103\n",
      "0.41605216\n",
      "0.31104204\n",
      "0.45596337\n",
      "0.43509585\n",
      "0.5466274\n",
      "0.45528156\n",
      "0.29886645\n",
      "0.5859236\n",
      "0.25832412\n",
      "0.26085398\n",
      "0.5232413\n",
      "0.43403342\n",
      "0.20788808\n",
      "0.25158334\n",
      "0.34380555\n",
      "0.27768892\n",
      "0.53862065\n",
      "0.42446065\n",
      "0.13007927\n",
      "0.3883475\n",
      "0.1903942\n",
      "0.32422805\n",
      "0.23554592\n",
      "0.242197\n",
      "0.45130795\n",
      "0.41435584\n",
      "0.44099876\n",
      "0.40070954\n",
      "0.34276235\n",
      "0.30551213\n",
      "0.36271173\n",
      "0.3682027\n",
      "0.4434531\n",
      "0.35045353\n",
      "0.31312293\n",
      "0.45073146\n",
      "0.2826567\n",
      "0.49206498\n",
      "0.40756297\n",
      "0.37781903\n",
      "0.25081712\n",
      "0.5180839\n",
      "0.25069708\n",
      "0.24955626\n",
      "0.45189458\n",
      "0.3086759\n",
      "0.5475692\n",
      "0.21381918\n",
      "0.2002741\n",
      "0.304605\n",
      "0.42097712\n",
      "0.35730833\n",
      "0.36516416\n",
      "0.5374192\n",
      "0.4516561\n",
      "0.43919304\n",
      "0.28233436\n",
      "0.5088782\n",
      "0.33452296\n",
      "0.34331203\n",
      "0.30471626\n",
      "0.42994806\n",
      "0.40065688\n",
      "0.4652849\n",
      "0.49192238\n",
      "0.25666037\n",
      "0.42805433\n",
      "0.5636089\n",
      "0.43146998\n",
      "0.32682025\n",
      "0.2560738\n",
      "0.35723162\n",
      "0.32860893\n",
      "0.42360097\n",
      "0.36501062\n",
      "0.25412703\n",
      "0.43678248\n",
      "0.49593413\n",
      "0.35100314\n",
      "0.44817165\n",
      "0.36680067\n",
      "0.20118836\n",
      "0.24204911\n",
      "0.53516066\n",
      "0.35029858\n",
      "0.30994233\n",
      "0.49592072\n",
      "0.47701257\n",
      "0.6194922\n",
      "0.17055896\n",
      "0.28197965\n",
      "0.31915164\n",
      "0.4451089\n",
      "0.3827629\n",
      "0.2531602\n",
      "0.49329215\n",
      "0.253964\n",
      "0.344437\n",
      "0.51892227\n",
      "0.3656575\n",
      "0.434337\n",
      "0.45252064\n",
      "0.27679083\n",
      "0.3541155\n",
      "0.29952952\n",
      "Validation\n",
      "Training and Validation Finish\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "loss_train = []\n",
    "loss_val = []\n",
    "for epoch in range(params[\"epochs\"]):\n",
    "    print(\"Epoch: %d\"%(epoch))\n",
    "    sess.run(iterator_train.initializer)\n",
    "    print(\"Training\")\n",
    "    while True:\n",
    "        try:\n",
    "            item_dict  = sess.run(next_item,feed_dict={handle: handle_train})\n",
    "            query= sess.run(seqModel.encoder_state,feed_dict={seqModel.sentence:item_dict[\"query\"]})\n",
    "            response= sess.run(seqModel.encoder_state,feed_dict={seqModel.sentence:item_dict[\"response\"]})\n",
    "            query = query[1]\n",
    "            response = response[1]\n",
    "            _, loss = sess.run([M.train_op, M.loss],feed_dict={\n",
    "                M.lr: params[\"learning_rate\"], \n",
    "                M.query: query,\n",
    "                M.response: response,\n",
    "                M.label: item_dict[\"label\"],\n",
    "                M.user: item_dict[\"user\"]\n",
    "            })\n",
    "            loss_train.append(loss)\n",
    "            print(loss)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        except tf.errors.DataLossError:\n",
    "            break\n",
    "    val_scores = []\n",
    "    print(\"Validation\")\n",
    "    predictions = []\n",
    "    for i in range(len(val)):\n",
    "        query = val[i][\"query\"]\n",
    "        user = val[i][\"user\"]\n",
    "        scores = []\n",
    "        query= sess.run(seqModel.encoder_state,feed_dict={seqModel.sentence:query})\n",
    "        query = query[1]\n",
    "        for j in range(10):\n",
    "            response = val[i][\"response_\"+str(j)]\n",
    "            response= sess.run(seqModel.encoder_state,feed_dict={seqModel.sentence:response})\n",
    "            response = response[1]\n",
    "            val_score = sess.run(M.predict,feed_dict={\n",
    "                M.query: query,\n",
    "                M.response: response,\n",
    "                M.user: user\n",
    "            })\n",
    "            scores.append(val_score)\n",
    "        predict = np.argmax(np.array(scores))\n",
    "        predictions.append(predict)\n",
    "        print(predict)\n",
    "\n",
    "print(\"Training and Validation Finish\")\n",
    "\n",
    "# Save Model\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, params[\"save_path\"])\n",
    "save_params(params)\n",
    "\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 3, 4, 9, 5, 1, 7, 4, 2, 4, 3, 3, 9, 4, 6, 4, 6, 9, 0, 6, 0, 1, 5, 8, 7, 6, 5, 3, 3, 3, 0, 2, 0, 4, 5, 3, 8, 6, 7, 9, 6, 5, 3, 5, 4, 0, 8, 3, 2, 8, 3, 9, 0, 3, 7, 5, 6, 4, 3, 3, 5, 8, 0, 2, 6, 4, 6, 8, 0, 9, 7, 2, 7, 2, 6, 3, 8, 1, 9, 9, 3, 5, 0, 2, 6, 2, 9, 3, 5, 1, 8, 3, 4, 1, 7, 1, 0, 3, 7, 3, 6, 3, 0, 9, 9, 8, 9, 6, 8, 4, 0, 0, 3, 1, 1, 7, 6, 9, 0, 1, 8, 3, 8, 3, 0, 4, 8, 0, 6, 5, 4, 3, 3, 1, 8, 7, 7, 3, 3, 4, 4, 3, 8, 3, 5, 6, 6, 8, 3, 2, 9, 7, 4, 8, 3, 0, 0, 5, 0, 9, 7, 9, 6, 2, 9, 3, 2, 6, 9, 9, 9, 3, 2, 9, 7, 1, 9, 7, 6, 0, 1, 6, 6, 8, 7, 4, 5, 5, 5, 0, 1, 4, 7, 1, 9, 8, 4, 8, 8, 4, 3, 0, 2, 7, 2, 9, 1, 1, 3, 2, 0, 4, 2, 3, 3, 2, 2, 4, 9, 6, 6, 8, 0, 5, 6, 1, 3, 2, 9, 3, 4, 3, 8, 4, 9, 5, 5, 0, 9, 7, 5, 6, 6, 7, 3, 0, 0, 4, 8, 3, 1, 8, 8, 6, 1, 4, 2, 2, 4, 6, 7, 8, 0, 1, 8, 7, 8, 0, 8, 2, 3, 2, 5, 7, 6, 5, 0, 0, 3, 4, 2, 1, 0, 6, 0, 3, 3, 4, 9, 4, 4, 3, 0, 2, 7, 6, 0, 7, 6, 2, 7, 4, 8, 6, 4, 4, 4, 1, 1, 5, 4, 5, 3, 0, 4, 9, 7, 1, 7, 0, 4, 0, 7, 9, 6, 8, 4, 4, 3, 0, 8, 3, 1, 7, 9, 0, 7, 2, 7, 3, 5, 0, 1, 8, 3, 9, 3, 6, 6, 8, 3, 3, 5, 1, 6, 8, 0, 6, 0, 1, 0, 8, 4, 0, 4, 4, 1, 7, 7, 0, 1, 0, 5, 4, 9, 3, 0, 8, 4, 5, 9, 7, 0, 2, 9, 2, 5, 1, 7, 5, 7, 0, 0, 9, 7, 3, 4, 5, 0, 7, 8, 7, 0, 0, 3, 4, 5, 7, 2, 8, 1, 8, 8, 7, 0, 1, 4, 7, 7, 2, 1, 8, 8, 2, 0, 8, 2, 5, 2, 4, 7, 7, 3, 9, 5, 9, 0, 5, 1, 5, 1, 7, 7, 9, 3, 4, 8, 0, 7, 8, 0, 6, 6, 2, 2, 6, 4, 7, 0, 6, 3, 1, 9, 1, 1, 8, 5, 2, 0, 0, 6, 8, 7, 3, 3, 6, 5, 7, 5, 8, 2, 2, 9, 6, 4, 6, 8, 5, 5, 4, 5, 7, 2, 0, 2, 0, 4, 0, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python36)",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
